{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9a2cece6362b4b608d4b963da7cc71ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_62e092474bd0474499ff53673e01db90",
              "IPY_MODEL_21239dd7ac9a4517a2eb7da20554bb0e",
              "IPY_MODEL_6cae134a2b5e4c66b792469f977ba8d0",
              "IPY_MODEL_1584007fa8394370b01e24d633797d62",
              "IPY_MODEL_c6bfd53b347749aca10f933bc8f61a6e"
            ],
            "layout": "IPY_MODEL_d71e6b16f11d46c69df992d2220e407f"
          }
        },
        "62e092474bd0474499ff53673e01db90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d170137a0e2419cb4362b5dbc434600",
            "placeholder": "​",
            "style": "IPY_MODEL_8b622c44740a452c903da07717e20781",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "21239dd7ac9a4517a2eb7da20554bb0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_4dea892a29204eadbbc4a00bab8bb1d2",
            "placeholder": "​",
            "style": "IPY_MODEL_ac0cf63d68fd49ecbc8ca05876b3d651",
            "value": ""
          }
        },
        "6cae134a2b5e4c66b792469f977ba8d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_52598276f2944a7095e530fa3f6a6dab",
            "style": "IPY_MODEL_42020b08fa844de68f62be190a5453a8",
            "value": true
          }
        },
        "1584007fa8394370b01e24d633797d62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_6db2813bbb304e5eb48b5d2b405fb076",
            "style": "IPY_MODEL_7855153aaf98444d9776754c88f7d0bc",
            "tooltip": ""
          }
        },
        "c6bfd53b347749aca10f933bc8f61a6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f0ce624d0914b4ba0e4873118aa8bee",
            "placeholder": "​",
            "style": "IPY_MODEL_1274345169164fe3902098243017777a",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "d71e6b16f11d46c69df992d2220e407f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "5d170137a0e2419cb4362b5dbc434600": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b622c44740a452c903da07717e20781": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4dea892a29204eadbbc4a00bab8bb1d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac0cf63d68fd49ecbc8ca05876b3d651": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52598276f2944a7095e530fa3f6a6dab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42020b08fa844de68f62be190a5453a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6db2813bbb304e5eb48b5d2b405fb076": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7855153aaf98444d9776754c88f7d0bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "9f0ce624d0914b4ba0e4873118aa8bee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1274345169164fe3902098243017777a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!rm -rf KoreanStandardPronunciation\n",
        "!git clone https://github.com/dhkang01/KoreanStandardPronunciation.git\n",
        "%cd KoreanStandardPronunciation\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQXr7aQYqQ-d",
        "outputId": "47f5024b-eb80-4067-aaf0-d69f132dab1d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'KoreanStandardPronunciation'...\n",
            "remote: Enumerating objects: 40, done.\u001b[K\n",
            "remote: Counting objects: 100% (40/40), done.\u001b[K\n",
            "remote: Compressing objects: 100% (34/34), done.\u001b[K\n",
            "remote: Total 40 (delta 19), reused 17 (delta 5), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (40/40), 108.31 KiB | 4.71 MiB/s, done.\n",
            "Resolving deltas: 100% (19/19), done.\n",
            "/content/KoreanStandardPronunciation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "save_dir = \"/content/drive/MyDrive/models/kocharelectra-pron-lora-adapter\"\n",
        "\n",
        "import os\n",
        "import json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCbLAYFmsJCb",
        "outputId": "b50f1d4d-7bf1-48c5-e093-f950ef6a2661"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q \"transformers>=4.38.0\" \"datasets>=2.18.0\" \"peft>=0.11.0\" accelerate huggingface_hub evaluate"
      ],
      "metadata": {
        "id": "R7c-gPQIWyx3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 511,
          "referenced_widgets": [
            "9a2cece6362b4b608d4b963da7cc71ee",
            "62e092474bd0474499ff53673e01db90",
            "21239dd7ac9a4517a2eb7da20554bb0e",
            "6cae134a2b5e4c66b792469f977ba8d0",
            "1584007fa8394370b01e24d633797d62",
            "c6bfd53b347749aca10f933bc8f61a6e",
            "d71e6b16f11d46c69df992d2220e407f",
            "5d170137a0e2419cb4362b5dbc434600",
            "8b622c44740a452c903da07717e20781",
            "4dea892a29204eadbbc4a00bab8bb1d2",
            "ac0cf63d68fd49ecbc8ca05876b3d651",
            "52598276f2944a7095e530fa3f6a6dab",
            "42020b08fa844de68f62be190a5453a8",
            "6db2813bbb304e5eb48b5d2b405fb076",
            "7855153aaf98444d9776754c88f7d0bc",
            "9f0ce624d0914b4ba0e4873118aa8bee",
            "1274345169164fe3902098243017777a"
          ]
        },
        "id": "UH7gLzX7SvVo",
        "outputId": "c040244e-584c-45c7-ebac-5460dd0278a7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9a2cece6362b4b608d4b963da7cc71ee"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset_id = \"dhkang01/KMA_dataset\"\n",
        "raw_ds = load_dataset(dataset_id, split=\"train\")\n",
        "\n",
        "raw_ds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnRX4nxUW1om",
        "outputId": "c5e12b9d-3363-47c3-ced4-095a255f28c0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['id', 'input', 'output'],\n",
              "    num_rows: 447115\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds_train_tmp = raw_ds.train_test_split(test_size=0.1, seed=42)\n",
        "train_ds = ds_train_tmp[\"train\"]\n",
        "tmp_ds   = ds_train_tmp[\"test\"]\n",
        "\n",
        "ds_val_test = tmp_ds.train_test_split(test_size=0.5, seed=42)\n",
        "val_ds = ds_val_test[\"train\"]\n",
        "test_ds = ds_val_test[\"test\"]\n",
        "\n",
        "# train/val/test -> 90/5/5\n",
        "\n",
        "train_ds = train_ds.select(range(10000))\n",
        "val_ds = val_ds.select(range(100))\n",
        "test_ds = test_ds.select(range(10))\n"
      ],
      "metadata": {
        "id": "pHHd_N49W40V"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenizer 다운로드"
      ],
      "metadata": {
        "id": "WFgn1ry0XLLl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from KoCharELECTRA.tokenization_kocharelectra import KoCharElectraTokenizer\n",
        "\n",
        "model_name = \"monologg/kocharelectra-small-discriminator\"\n",
        "\n",
        "tokenizer = KoCharElectraTokenizer.from_pretrained(model_name)\n",
        "print(tokenizer.tokenize(\"가나다\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9JuUUxXW6Ke",
        "outputId": "c5b0f51a-9c78-46a0-f6ee-85b0010999b2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'ElectraTokenizer'. \n",
            "The class this function is called from is 'KoCharElectraTokenizer'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['가', '나', '다']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "output vocab"
      ],
      "metadata": {
        "id": "mSW8hqgWZCeA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "\n",
        "# tokenizer.vocab은 OrderedDict(토큰 → ID)\n",
        "token_list = list(tokenizer.vocab.keys())\n",
        "\n",
        "pron2id = OrderedDict()\n",
        "for idx, tok in enumerate(token_list):\n",
        "    pron2id[tok] = idx\n",
        "\n",
        "id2pron = {v: k for k, v in pron2id.items()}\n",
        "\n",
        "len(pron2id), list(list(pron2id.items())[:10])"
      ],
      "metadata": {
        "id": "Ac7KYkFwW9xP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcc41b82-5b29-413d-ee86-1ab7e47235e7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11568,\n",
              " [('[PAD]', 0),\n",
              "  ('[UNK]', 1),\n",
              "  ('[CLS]', 2),\n",
              "  ('[SEP]', 3),\n",
              "  ('[MASK]', 4),\n",
              "  (' ', 5),\n",
              "  ('이', 6),\n",
              "  ('다', 7),\n",
              "  ('는', 8),\n",
              "  ('에', 9)])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "전처리 함수 정의 및 적용\n",
        "\n",
        "복수 발음 허용 X"
      ],
      "metadata": {
        "id": "C_BE4tNIMB8L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "max_length = 128  # 필요에 따라 조절\n",
        "\n",
        "def preprocess_example(example):\n",
        "    text = example[\"input\"]\n",
        "    pron = example[\"output\"]  # List[List[str]]\n",
        "\n",
        "    # KoCharElectra는 char 단위 토큰 + [CLS], [SEP]\n",
        "    encoding = tokenizer(\n",
        "        text,\n",
        "        truncation=True,\n",
        "        max_length=max_length,\n",
        "        padding=\"max_length\",  # DataCollator 써도 되지만 여기서는 고정 길이로\n",
        "        return_tensors=None,\n",
        "    )\n",
        "\n",
        "    input_ids = encoding[\"input_ids\"]\n",
        "    attention_mask = encoding[\"attention_mask\"]\n",
        "\n",
        "    # Electra/KoCharElectra: 대체로 [CLS] + chars + [SEP]\n",
        "    # => 실제 문자 수 = len(text)\n",
        "    # => pron 길이와 len(text)가 맞는다고 가정 (안 맞는 샘플은 나중에 필터 가능)\n",
        "    seq_len = sum(attention_mask)  # 실제 non-pad 길이\n",
        "    # [CLS] at 0, [SEP] at seq_len-1, chars in 1..seq_len-2\n",
        "\n",
        "    labels = np.full_like(input_ids, fill_value=-100)  # default ignore_index\n",
        "\n",
        "    # 문자 수와 pron 길이 안 맞으면 그냥 전부 ignore(-100)로 두고 스킵되게 할 수도 있음\n",
        "    # 여기선 일단 최소한으로만 체크\n",
        "    n_chars = seq_len - 2  # CLS, SEP 제외\n",
        "\n",
        "    if len(pron) != n_chars:\n",
        "        # 불일치하는 경우: 전부 padding label로 두고, 나중에 이런 샘플 비율 보고 판단\n",
        "        print(f\"Warning: pron len {len(pron)} != n_chars {n_chars} for text: {text}\")\n",
        "        print(f\"in the case, pron: {\"\".join([l[0] for l in pron])}\")\n",
        "        encoding[\"labels\"] = labels.tolist()\n",
        "        return encoding\n",
        "\n",
        "    for i in range(len(pron)):\n",
        "        cand_list = pron[i]\n",
        "        if not cand_list:\n",
        "            continue\n",
        "        label_id = pron2id[cand_list[0]]               # 첫 후보를 gold label로 사용\n",
        "        if label_id < 6:                               # 특수토큰, 띄어쓰기는 사용 X\n",
        "            continue\n",
        "\n",
        "        token_pos = 1 + i                      # 0: [CLS], 1.. : chars\n",
        "        if token_pos < seq_len - 1:            # 마지막 [SEP] 전까지만\n",
        "            labels[token_pos] = label_id\n",
        "\n",
        "    encoding[\"labels\"] = labels.tolist()\n",
        "    return encoding"
      ],
      "metadata": {
        "id": "WL0yWezbW_J5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_tokenized = train_ds.map(\n",
        "    preprocess_example,\n",
        "    remove_columns=train_ds.column_names,\n",
        ")\n",
        "\n",
        "val_tokenized = val_ds.map(\n",
        "    preprocess_example,\n",
        "    remove_columns=val_ds.column_names,\n",
        ")\n",
        "\n",
        "test_tokenized = test_ds.map(\n",
        "    preprocess_example,\n",
        "    remove_columns=val_ds.column_names,\n",
        ")\n",
        "\n",
        "# too long seq is out.\n",
        "\n",
        "# train_tokenized[0]\n"
      ],
      "metadata": {
        "id": "fWYWScxeXBJD",
        "collapsed": true
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 로드, LoRA 적용\n",
        "\n",
        "encoder에 LoRA적용\n",
        "classifier에 LoRA적용X, 전부 trainable"
      ],
      "metadata": {
        "id": "AQJtsdUuZsz2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForTokenClassification\n",
        "\n",
        "num_labels = len(pron2id)\n",
        "\n",
        "base_model = AutoModelForTokenClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=num_labels,\n",
        ")\n"
      ],
      "metadata": {
        "id": "iPrWeE7UZv5V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "556b026a-4904-4fea-9e60-696294a99b67"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ElectraForTokenClassification were not initialized from the model checkpoint at monologg/kocharelectra-small-discriminator and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    task_type=TaskType.TOKEN_CLS,\n",
        "    r=16,\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"none\",\n",
        "    target_modules=[\"query\", \"key\", \"value\", \"dense\"]  # Electra의 attention/FFN 모듈 이름 기준\n",
        ")\n",
        "\n",
        "model = get_peft_model(base_model, lora_config)\n",
        "model.print_trainable_parameters()\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "id": "EfF1Z-tBZxt7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "773cd33b-3c5a-490e-9e99-159c04b71d46",
        "collapsed": true
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 3,857,712 || all params: 17,887,584 || trainable%: 21.5664\n",
            "PeftModelForTokenClassification(\n",
            "  (base_model): LoraModel(\n",
            "    (model): ElectraForTokenClassification(\n",
            "      (electra): ElectraModel(\n",
            "        (embeddings): ElectraEmbeddings(\n",
            "          (word_embeddings): Embedding(11568, 128, padding_idx=0)\n",
            "          (position_embeddings): Embedding(512, 128)\n",
            "          (token_type_embeddings): Embedding(2, 128)\n",
            "          (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (embeddings_project): Linear(in_features=128, out_features=256, bias=True)\n",
            "        (encoder): ElectraEncoder(\n",
            "          (layer): ModuleList(\n",
            "            (0-11): 12 x ElectraLayer(\n",
            "              (attention): ElectraAttention(\n",
            "                (self): ElectraSelfAttention(\n",
            "                  (query): lora.Linear(\n",
            "                    (base_layer): Linear(in_features=256, out_features=256, bias=True)\n",
            "                    (lora_dropout): ModuleDict(\n",
            "                      (default): Dropout(p=0.1, inplace=False)\n",
            "                    )\n",
            "                    (lora_A): ModuleDict(\n",
            "                      (default): Linear(in_features=256, out_features=16, bias=False)\n",
            "                    )\n",
            "                    (lora_B): ModuleDict(\n",
            "                      (default): Linear(in_features=16, out_features=256, bias=False)\n",
            "                    )\n",
            "                    (lora_embedding_A): ParameterDict()\n",
            "                    (lora_embedding_B): ParameterDict()\n",
            "                    (lora_magnitude_vector): ModuleDict()\n",
            "                  )\n",
            "                  (key): lora.Linear(\n",
            "                    (base_layer): Linear(in_features=256, out_features=256, bias=True)\n",
            "                    (lora_dropout): ModuleDict(\n",
            "                      (default): Dropout(p=0.1, inplace=False)\n",
            "                    )\n",
            "                    (lora_A): ModuleDict(\n",
            "                      (default): Linear(in_features=256, out_features=16, bias=False)\n",
            "                    )\n",
            "                    (lora_B): ModuleDict(\n",
            "                      (default): Linear(in_features=16, out_features=256, bias=False)\n",
            "                    )\n",
            "                    (lora_embedding_A): ParameterDict()\n",
            "                    (lora_embedding_B): ParameterDict()\n",
            "                    (lora_magnitude_vector): ModuleDict()\n",
            "                  )\n",
            "                  (value): lora.Linear(\n",
            "                    (base_layer): Linear(in_features=256, out_features=256, bias=True)\n",
            "                    (lora_dropout): ModuleDict(\n",
            "                      (default): Dropout(p=0.1, inplace=False)\n",
            "                    )\n",
            "                    (lora_A): ModuleDict(\n",
            "                      (default): Linear(in_features=256, out_features=16, bias=False)\n",
            "                    )\n",
            "                    (lora_B): ModuleDict(\n",
            "                      (default): Linear(in_features=16, out_features=256, bias=False)\n",
            "                    )\n",
            "                    (lora_embedding_A): ParameterDict()\n",
            "                    (lora_embedding_B): ParameterDict()\n",
            "                    (lora_magnitude_vector): ModuleDict()\n",
            "                  )\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): ElectraSelfOutput(\n",
            "                  (dense): lora.Linear(\n",
            "                    (base_layer): Linear(in_features=256, out_features=256, bias=True)\n",
            "                    (lora_dropout): ModuleDict(\n",
            "                      (default): Dropout(p=0.1, inplace=False)\n",
            "                    )\n",
            "                    (lora_A): ModuleDict(\n",
            "                      (default): Linear(in_features=256, out_features=16, bias=False)\n",
            "                    )\n",
            "                    (lora_B): ModuleDict(\n",
            "                      (default): Linear(in_features=16, out_features=256, bias=False)\n",
            "                    )\n",
            "                    (lora_embedding_A): ParameterDict()\n",
            "                    (lora_embedding_B): ParameterDict()\n",
            "                    (lora_magnitude_vector): ModuleDict()\n",
            "                  )\n",
            "                  (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): ElectraIntermediate(\n",
            "                (dense): lora.Linear(\n",
            "                  (base_layer): Linear(in_features=256, out_features=1024, bias=True)\n",
            "                  (lora_dropout): ModuleDict(\n",
            "                    (default): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (lora_A): ModuleDict(\n",
            "                    (default): Linear(in_features=256, out_features=16, bias=False)\n",
            "                  )\n",
            "                  (lora_B): ModuleDict(\n",
            "                    (default): Linear(in_features=16, out_features=1024, bias=False)\n",
            "                  )\n",
            "                  (lora_embedding_A): ParameterDict()\n",
            "                  (lora_embedding_B): ParameterDict()\n",
            "                  (lora_magnitude_vector): ModuleDict()\n",
            "                )\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): ElectraOutput(\n",
            "                (dense): lora.Linear(\n",
            "                  (base_layer): Linear(in_features=1024, out_features=256, bias=True)\n",
            "                  (lora_dropout): ModuleDict(\n",
            "                    (default): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (lora_A): ModuleDict(\n",
            "                    (default): Linear(in_features=1024, out_features=16, bias=False)\n",
            "                  )\n",
            "                  (lora_B): ModuleDict(\n",
            "                    (default): Linear(in_features=16, out_features=256, bias=False)\n",
            "                  )\n",
            "                  (lora_embedding_A): ParameterDict()\n",
            "                  (lora_embedding_B): ParameterDict()\n",
            "                  (lora_magnitude_vector): ModuleDict()\n",
            "                )\n",
            "                (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (classifier): ModulesToSaveWrapper(\n",
            "        (original_module): Linear(in_features=256, out_features=11568, bias=True)\n",
            "        (modules_to_save): ModuleDict(\n",
            "          (default): Linear(in_features=256, out_features=11568, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "char_embed 설정\n",
        "\n",
        "char->vec(31dim)\n",
        "\n",
        "emb wrapping"
      ],
      "metadata": {
        "id": "c7YXVgAfekl_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 feature index:\n",
        "# 0: stop, 1: fricative, 2: affricate, 3: nasal, 4: liquid,\n",
        "# 5: labial, 6: coronal, 7: dorsal, 8: glottal,\n",
        "# 9: tense, 10: aspirated\n",
        "\n",
        "CONSONANT_FEATURES = {\n",
        "    \"ㄱ\": [1,0,0,0,0,  0,0,1,0, 0,0],  # velar stop\n",
        "    \"ㄲ\": [1,0,0,0,0,  0,0,1,0, 1,0],  # tense velar stop\n",
        "    \"ㄴ\": [0,0,0,1,0,  0,1,0,0, 0,0],  # coronal nasal\n",
        "    \"ㄷ\": [1,0,0,0,0,  0,1,0,0, 0,0],  # coronal stop\n",
        "    \"ㄸ\": [1,0,0,0,0,  0,1,0,0, 1,0],  # tense coronal stop\n",
        "    \"ㄹ\": [0,0,0,0,1,  0,1,0,0, 0,0],  # coronal liquid\n",
        "    \"ㅁ\": [0,0,0,1,0,  1,0,0,0, 0,0],  # labial nasal\n",
        "    \"ㅂ\": [1,0,0,0,0,  1,0,0,0, 0,0],  # labial stop\n",
        "    \"ㅃ\": [1,0,0,0,0,  1,0,0,0, 1,0],  # tense labial stop\n",
        "    \"ㅅ\": [0,1,0,0,0,  0,1,0,0, 0,0],  # coronal fricative\n",
        "    \"ㅆ\": [0,1,0,0,0,  0,1,0,0, 1,0],  # tense coronal fricative\n",
        "    \"ㅇ\": [0,0,0,1,0,  0,0,1,0, 0,0],  # velar nasal (종성 기준)\n",
        "    \"ㅈ\": [0,0,1,0,0,  0,1,0,0, 0,0],  # coronal affricate\n",
        "    \"ㅉ\": [0,0,1,0,0,  0,1,0,0, 1,0],  # tense coronal affricate\n",
        "    \"ㅊ\": [0,0,1,0,0,  0,1,0,0, 0,1],  # aspirated coronal affricate\n",
        "    \"ㅋ\": [1,0,0,0,0,  0,0,1,0, 0,1],  # aspirated velar stop\n",
        "    \"ㅌ\": [1,0,0,0,0,  0,1,0,0, 0,1],  # aspirated coronal stop\n",
        "    \"ㅍ\": [1,0,0,0,0,  1,0,0,0, 0,1],  # aspirated labial stop\n",
        "    \"ㅎ\": [0,1,0,0,0,  0,0,0,1, 0,1],  # glottal fricative, aspirated\n",
        "}\n",
        "\n",
        "CODA_COMPOUND = {\n",
        "    \"ㄳ\": (\"ㄱ\", \"ㅅ\"),\n",
        "    \"ㄵ\": (\"ㄴ\", \"ㅈ\"),\n",
        "    \"ㄶ\": (\"ㄴ\", \"ㅎ\"),\n",
        "    \"ㄺ\": (\"ㄹ\", \"ㄱ\"),\n",
        "    \"ㄻ\": (\"ㄹ\", \"ㅁ\"),\n",
        "    \"ㄼ\": (\"ㄹ\", \"ㅂ\"),\n",
        "    \"ㄽ\": (\"ㄹ\", \"ㅅ\"),\n",
        "    \"ㄾ\": (\"ㄹ\", \"ㅌ\"),\n",
        "    \"ㄿ\": (\"ㄹ\", \"ㅍ\"),\n",
        "    \"ㅀ\": (\"ㄹ\", \"ㅎ\"),\n",
        "    \"ㅄ\": (\"ㅂ\", \"ㅅ\"),\n",
        "}\n"
      ],
      "metadata": {
        "id": "hAoL0B8DnkPG"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vowel feature index:\n",
        "# 0: high, 1: mid, 2: low,\n",
        "# 3: front, 4: central, 5: back,\n",
        "# 6: round, 7: tense, 8: diphthong\n",
        "\n",
        "BASE_VOWEL_FEATURES = {\n",
        "    \"ㅏ\": [0,0,1,  0,0,1,  0,1,0],  # low back unround, tense-ish\n",
        "    \"ㅓ\": [0,1,0,  0,0,1,  0,0,0],  # mid back unround, lax-ish\n",
        "    \"ㅗ\": [0,1,0,  0,0,1,  1,1,0],  # mid back round, tense-ish\n",
        "    \"ㅜ\": [0,1,0,  0,0,1,  1,0,0],  # mid back round, lax-ish\n",
        "    \"ㅡ\": [0,1,0,  0,1,0,  0,0,0],  # mid central unround\n",
        "    \"ㅣ\": [1,0,0,  1,0,0,  0,1,0],  # high front unround, tense\n",
        "\n",
        "    \"ㅐ\": [0,1,0,  1,0,0,  0,1,0],  # mid front unround, tense\n",
        "    \"ㅔ\": [0,1,0,  1,0,0,  0,0,0],  # mid front unround, lax-ish\n",
        "\n",
        "    # 필요하면 ㅚ, ㅟ, ㅢ도 base로 직접 정의 가능\n",
        "    \"ㅚ\": [0,1,0,  0,0,1,  1,1,0],  # /we/ or /ø/ 계열\n",
        "    \"ㅟ\": [1,0,0,  1,0,0,  1,1,0],  # /y/ 계열\n",
        "    \"ㅢ\": [0,1,0,  0,1,0,  0,1,0],  # central-ish compound\n",
        "}\n",
        "\n",
        "COMPOSED_VOWELS = {\n",
        "    \"ㅑ\": (\"ㅣ\", \"ㅏ\"),\n",
        "    \"ㅒ\": (\"ㅣ\", \"ㅐ\"),\n",
        "    \"ㅕ\": (\"ㅣ\", \"ㅓ\"),\n",
        "    \"ㅖ\": (\"ㅣ\", \"ㅔ\"),\n",
        "    \"ㅛ\": (\"ㅣ\", \"ㅗ\"),\n",
        "    \"ㅠ\": (\"ㅣ\", \"ㅜ\"),\n",
        "\n",
        "    \"ㅘ\": (\"ㅗ\", \"ㅏ\"),\n",
        "    \"ㅙ\": (\"ㅗ\", \"ㅐ\"),\n",
        "    \"ㅝ\": (\"ㅜ\", \"ㅓ\"),\n",
        "    \"ㅞ\": (\"ㅜ\", \"ㅔ\"),\n",
        "}"
      ],
      "metadata": {
        "id": "d5QW3Yg_oIj1"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_consonant_feature(jamo):\n",
        "    if jamo in CONSONANT_FEATURES:\n",
        "        return np.array(CONSONANT_FEATURES[jamo], dtype=np.float32)\n",
        "\n",
        "    if jamo in CODA_COMPOUND:\n",
        "        a, b = CODA_COMPOUND[jamo]\n",
        "        return (get_consonant_feature(a) + get_consonant_feature(b)) / 2\n",
        "\n",
        "    raise ValueError(f\"Unknown consonant: {jamo}\")\n",
        "\n",
        "\n",
        "def get_vowel_feature(jamo):\n",
        "    if jamo in BASE_VOWEL_FEATURES:\n",
        "        return np.array(BASE_VOWEL_FEATURES[jamo], dtype=np.float32)\n",
        "\n",
        "    if jamo in COMPOSED_VOWELS:\n",
        "        a, b = COMPOSED_VOWELS[jamo]\n",
        "        return (get_vowel_feature(a) + get_vowel_feature(b)) / 2\n",
        "\n",
        "    raise ValueError(f\"Unknown vowel: {jamo}\")"
      ],
      "metadata": {
        "id": "40zkIoveoWD_"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ONSETS  = list(\"ㄱㄲㄴㄷㄸㄹㅁㅂㅃㅅㅆㅇㅈㅉㅊㅋㅌㅍㅎ\")\n",
        "NUCLEI  = list(\"ㅏㅐㅑㅒㅓㅔㅕㅖㅗㅘㅙㅚㅛㅜㅝㅞㅟㅠㅡㅢㅣ\")\n",
        "CODAS   = [\"\"] + list(\"ㄱㄲㄳㄴㄵㄶㄷㄹㄺㄻㄼㄽㄾㄿㅀㅁㅂㅄㅅㅆㅇㅈㅊㅋㅌㅍㅎ\")\n",
        "\n",
        "def decompose(syllable):\n",
        "    code = ord(syllable) - 0xAC00\n",
        "    onset_idx = code // 588\n",
        "    nucleus_idx = (code % 588) // 28\n",
        "    coda_idx = code % 28\n",
        "\n",
        "    onset = ONSETS[onset_idx]\n",
        "    nucleus = NUCLEI[nucleus_idx]\n",
        "    coda = CODAS[coda_idx] if coda_idx != 0 else None\n",
        "\n",
        "    return onset, nucleus, coda"
      ],
      "metadata": {
        "id": "OgEFKF69p7jp"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_syllable_feature(syllable):\n",
        "    onset, nucleus, coda = decompose(syllable)\n",
        "\n",
        "    onset_feat  = get_consonant_feature(onset)     # 11D\n",
        "    nucleus_feat = get_vowel_feature(nucleus)      # 9D\n",
        "\n",
        "    if coda is None:\n",
        "        coda_feat = np.zeros(11)                 # 종성 없음 → 11D zero\n",
        "    else:\n",
        "        coda_feat = get_consonant_feature(coda)  # 11D\n",
        "\n",
        "    return np.concatenate([onset_feat, nucleus_feat, coda_feat])  # 31D\n",
        "\n",
        "\n",
        "char_embed = np.zeros((len(pron2id), 31), dtype=np.float32) # (11568, 31)\n",
        "print(char_embed.shape)\n",
        "\n",
        "for pron, idx in pron2id.items():\n",
        "    if len(pron) != 1:\n",
        "        continue\n",
        "    if ord(pron) < ord('가'):\n",
        "        continue\n",
        "    if ord('힣') < ord(pron):\n",
        "        continue\n",
        "    char_embed[idx] = get_syllable_feature(pron)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYbfOlceqALq",
        "outputId": "87a72d21-f733-42e0-9c14-a1a062e6ee13"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(11568, 31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "char_embed = torch.from_numpy(char_embed)"
      ],
      "metadata": {
        "id": "sjMlNCXOM-Za"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NewEmb:\n",
        "```\n",
        "char  ->  OldEmb  ->  emb\n",
        "    + 31dim -> 128dim +\n",
        "```\n",
        "\n",
        "31dim: 발음정보 고정 emb\n",
        "128dim: 학습가능, Dense layer"
      ],
      "metadata": {
        "id": "5pGASGcttYTP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class ElectraEmbeddingWithNew(nn.Module):\n",
        "    def __init__(self, electra_embeddings, electra_embeddings_project, char_embed):\n",
        "        super().__init__()\n",
        "        self.old = electra_embeddings                  # 기존 ElectraEmbeddings\n",
        "        self.proj = electra_embeddings_project\n",
        "\n",
        "        # new embedding (11568X31), 학습하지 않음\n",
        "        self.register_buffer(\"char_embed\", char_embed, persistent=True)\n",
        "\n",
        "        # new embedding → 256 projection\n",
        "        self.new_up = nn.Linear(31, 256)\n",
        "        nn.init.zeros_(self.new_up.weight)\n",
        "        nn.init.zeros_(self.new_up.bias)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids=None,\n",
        "        token_type_ids=None,\n",
        "        position_ids=None,\n",
        "        inputs_embeds=None,\n",
        "        past_key_values_length=0,\n",
        "    ):\n",
        "      # HF ElectraEmbeddings의 원래 forward와 동일한 시그니처로 맞추고,\n",
        "      # 내부에서 self.old(...) 를 그대로 호출하는 방식이 더 안전함.\n",
        "\n",
        "        # ---- Electra projection ----\n",
        "        old_emb_128 = self.old(\n",
        "            input_ids=input_ids,\n",
        "            token_type_ids=token_type_ids,\n",
        "            position_ids=position_ids,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            past_key_values_length=past_key_values_length,\n",
        "        )\n",
        "        old_emb_256 = self.proj(old_emb_128)\n",
        "\n",
        "        # ---- new embedding 31 차원 ----\n",
        "        new_emb_31 = self.char_embed[input_ids]     # (B, L, 31)\n",
        "        new_emb_256 = self.new_up(new_emb_31)\n",
        "\n",
        "        # ---- 256 차원에서 add ----\n",
        "        final_emb = old_emb_256 + new_emb_256\n",
        "        return final_emb, new_emb_256\n"
      ],
      "metadata": {
        "id": "5tCtwIKfeyA1"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Concat wrapper 모듈 적용\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5xhGm5XXVh_t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ElectraWithCharEmbedding(nn.Module):\n",
        "    \"\"\"\n",
        "    - peft_model.base_model.electra 를 backbone으로 사용\n",
        "    - electra.embeddings 를 ElectraEmbeddingWithNew 로 교체\n",
        "    - forward에서는 encoder 통과 후:\n",
        "      - sequence_output (encoder output)\n",
        "      - embedding_output (입력 임베딩)\n",
        "      을 함께 반환\n",
        "    \"\"\"\n",
        "    def __init__(self, peft_model, char_embed):\n",
        "        super().__init__()\n",
        "        self.peft_model = peft_model              # PeftModelForTokenClassification\n",
        "\n",
        "        # ElectraModel (LoRA 포함)\n",
        "        electra = peft_model.base_model.electra\n",
        "\n",
        "        # electra emb 교체\n",
        "        new_emb = ElectraEmbeddingWithNew(\n",
        "            electra.embeddings,\n",
        "            electra.embeddings_project,\n",
        "            char_embed\n",
        "        )\n",
        "        electra.embeddings = new_emb\n",
        "        electra.embeddings_project = None\n",
        "\n",
        "        # char_embed를 바깥에서 접근할 수 있게 노출\n",
        "        self.char_embed = new_emb.char_embed      # (vocab_size, 31)\n",
        "        self.config = peft_model.base_model.config\n",
        "        self.hidden_size = self.config.hidden_size\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids=None,\n",
        "        attention_mask=None,\n",
        "        token_type_ids=None,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        # 0) define electra\n",
        "        electra = self.peft_model.base_model.electra\n",
        "\n",
        "        # 1) input embedding\n",
        "        embedding_output, new_embedding_output = electra.embeddings(\n",
        "            input_ids=input_ids,\n",
        "            token_type_ids=token_type_ids,\n",
        "        )  # (B, L, embed_dim=hidden_size)\n",
        "\n",
        "        # 2) attention mask / head mask\n",
        "        extended_mask = electra.get_extended_attention_mask(\n",
        "            attention_mask,\n",
        "            input_shape=input_ids.shape,\n",
        "            device=input_ids.device,\n",
        "        )\n",
        "\n",
        "        head_mask = electra.get_head_mask(\n",
        "            None, electra.config.num_hidden_layers\n",
        "        )\n",
        "\n",
        "        # 3) encoder 출력 (LoRA 적용됨)\n",
        "        encoder_outputs = electra.encoder(\n",
        "            embedding_output,\n",
        "            attention_mask=extended_mask,\n",
        "            head_mask=head_mask,\n",
        "            output_attentions=electra.config.output_attentions,\n",
        "            output_hidden_states=electra.config.output_hidden_states,\n",
        "            return_dict=True,\n",
        "        )\n",
        "\n",
        "        sequence_output = encoder_outputs.last_hidden_state  # (B, L, hidden_size)\n",
        "\n",
        "        # 필요하면 encoder_outputs도 같이 넘길 수 있음\n",
        "        return {\n",
        "            \"sequence_output\": sequence_output,\n",
        "            \"embedding_output\": new_embedding_output, # new emb(only pron info)\n",
        "            # \"encoder_outputs\": encoder_outputs,\n",
        "        }\n"
      ],
      "metadata": {
        "id": "IL9E_IDh8kx1"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PronunciationRNNCell(nn.Module):\n",
        "    \"\"\"\n",
        "    한 스텝에서:\n",
        "      seq_state, emb_256 -> concat -> new_seq, emb_31, is_end_logit\n",
        "    - seq_state: (B, H_enc) (Electra hidden)\n",
        "    - emb_256:  (B, H_emb)  (Embedding output)\n",
        "    - new_seq:  (B, H_enc)  (다음 step hidden)\n",
        "    - emb_31:   (B, 31)     (예측 phoneme embedding)\n",
        "    - is_end_logit: (B, 1)  (EOS 여부 logit, sigmoid로 확률)\n",
        "    \"\"\"\n",
        "    def __init__(self, hidden_size_rnn: int, enc_dim: int, out_embed_dim: int = 31):\n",
        "        super().__init__()\n",
        "        self.hidden_size_rnn = hidden_size_rnn\n",
        "        self.enc_dim = enc_dim\n",
        "        self.out_embed_dim = out_embed_dim\n",
        "\n",
        "        self.in_act = nn.GELU()\n",
        "\n",
        "        self.fc = nn.Linear(hidden_size_rnn + enc_dim, hidden_size_rnn+out_embed_dim+1)\n",
        "\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, seq_state, emb_256):\n",
        "        # seq_state: (B, H_enc)\n",
        "        # emb_256:  (B, H_enc)\n",
        "        x = torch.cat([seq_state, emb_256], dim=-1)          # (B, H_enc+H_enc)\n",
        "        x = self.in_act(x)\n",
        "\n",
        "        out = self.fc(x)\n",
        "        new_seq = torch.tanh(out[:, :self.hidden_size_rnn])                     # (B, H_enc)\n",
        "        out_dim = self.hidden_size_rnn+self.out_embed_dim\n",
        "        emb_31 = self.sigmoid(out[:, self.hidden_size_rnn:self.hidden_size_rnn+self.out_embed_dim])                      # (B, 31)\n",
        "        is_end_logit = self.sigmoid(out[:, out_dim:out_dim+1])              # (B, 1)\n",
        "\n",
        "        return new_seq, emb_31, is_end_logit\n"
      ],
      "metadata": {
        "id": "GsSNLbKr-wch"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PronunciationTaggerRNN(nn.Module):\n",
        "    \"\"\"\n",
        "    ElectraWithCharEmbedding을 backbone으로 사용하는 RNN 기반 발음 tagger.\n",
        "\n",
        "    - backbone:\n",
        "        input_ids, attention_mask, token_type_ids ->\n",
        "        sequence_output (B, L, H), embedding_output (B, L, H)\n",
        "\n",
        "    - 이 모델:\n",
        "        fusion_t = sequence_output_t + embedding_output_t (각 토큰 위치)\n",
        "        seq_state_0 = 0\n",
        "        for t in 1..L:\n",
        "            seq_state_t, emb_31_t, is_end_logit_t = RNNCell(seq_state_{t-1}, fusion_t)\n",
        "\n",
        "        -> emb_31: (B, L, 31)\n",
        "        -> is_end_logit: (B, L, 1)\n",
        "\n",
        "    학습 시:\n",
        "        - labels: (B, L), ignore_index=-100\n",
        "        - target_embed = char_embed[labels]\n",
        "        - emb_31와의 MSE를 token-wise로 계산\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        backbone: ElectraWithCharEmbedding,\n",
        "        num_labels: int,\n",
        "        ignore_index: int = -100,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.backbone = backbone\n",
        "        self.ignore_index = ignore_index\n",
        "        self.num_labels = num_labels\n",
        "\n",
        "        self.config = backbone.config\n",
        "        self.hidden_size_rnn = backbone.hidden_size     # H_enc (e.g., 256)\n",
        "\n",
        "        # RNN cell\n",
        "        self.cell = PronunciationRNNCell(\n",
        "            hidden_size_rnn=self.hidden_size_rnn,\n",
        "            enc_dim=self.hidden_size_rnn,\n",
        "            out_embed_dim=backbone.char_embed.size(1),  # 31\n",
        "        )\n",
        "\n",
        "        # char_embed (vocab_size, 31)\n",
        "        self.char_embed = backbone.char_embed\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids=None,\n",
        "        attention_mask=None,\n",
        "        token_type_ids=None,\n",
        "        labels=None,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        # 1) backbone 출력\n",
        "        backbone_outputs = self.backbone(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            **kwargs,\n",
        "        )\n",
        "        seq_out = backbone_outputs[\"sequence_output\"]   # (B, L, H_enc)\n",
        "        emb_out = backbone_outputs[\"embedding_output\"]  # (B, L, H_enc)\n",
        "\n",
        "        B, L, H_enc = seq_out.shape\n",
        "        if seq_out.shape != emb_out.shape:\n",
        "            raise ValueError(f\"seq_out.shape({seq_out.shape}) != emb_out.shape({emb_out.shape})\")\n",
        "\n",
        "        seq_state = seq_out.reshape(B * L, H_enc)\n",
        "        emb_state = emb_out.reshape(B * L, H_enc)\n",
        "\n",
        "        pred_emb_list = []\n",
        "        is_end_logit = False\n",
        "\n",
        "        while True:\n",
        "            # 원래는 2-3회 정도 실시\n",
        "            seq_state, emb_31_t, is_end_logit = self.cell(seq_state, emb_state)\n",
        "            pred_emb_list.append(emb_31_t.unsqueeze(1))        # (B*L, 1, 31)\n",
        "\n",
        "            break # don't use end_logit, use only one output\n",
        "\n",
        "        pred_embed = torch.cat(pred_emb_list, dim=1).reshape(B, L, 31)        # (B*L, 1, 31) -> (B, L, 31)\n",
        "\n",
        "        # ===========================================================\n",
        "        # 5) Loss 계산\n",
        "        # ===========================================================\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            # labels: (B, L)\n",
        "            with torch.no_grad():\n",
        "                labels_clamped = labels.clone()\n",
        "                labels_clamped = labels_clamped.masked_fill(\n",
        "                    labels_clamped == self.ignore_index, 0\n",
        "                )\n",
        "                char_embed = self.char_embed.to(labels_clamped.device)\n",
        "                labels_clamped = labels_clamped.to(char_embed.device)\n",
        "\n",
        "                target_embed = char_embed[labels_clamped]  # (B, L, 31)\n",
        "\n",
        "            mse = (pred_embed - target_embed) ** 2              # (B, L, 1)\n",
        "            mask = (labels != self.ignore_index).unsqueeze(-1)  # (B, L, 1)\n",
        "            mse = mse * mask\n",
        "\n",
        "            denom = mask.sum().clamp(min=1) # count\n",
        "            loss = mse.sum() / denom\n",
        "\n",
        "        # ===========================================================\n",
        "        # 6) 최종 return\n",
        "        # ===========================================================\n",
        "        return {\n",
        "            \"loss\": loss,\n",
        "            \"logits\": pred_embed,      # 예측된 31차원 phoneme embedding\n",
        "            # \"is_end_logits\": is_end_logits,  # EOS 여부 (미사용 가능)\n",
        "        }\n",
        "\n",
        "    def predict_chars(self, logits):\n",
        "        \"\"\"\n",
        "        logits: (B, L, D)\n",
        "        return: pred_ids (B, L)  - 각 위치별로 '가','나' 같은 발음 vocab index\n",
        "        \"\"\"\n",
        "\n",
        "        # 2) (B, L, 31) -> (B*L, 31)\n",
        "        B, L, D = logits.shape\n",
        "        pred_flat = logits.reshape(B * L, D)\n",
        "\n",
        "        # 3) char_embed와 같은 device로 맞추기\n",
        "        char_embed = self.char_embed.to(pred_flat.device)   # (V, 31)\n",
        "\n",
        "        # 4) L2 distance 기준으로 가장 가까운 발음 index 찾기\n",
        "        #    dist^2 = ||x - e||^2 = ||x||^2 + ||e||^2 - 2 x·e\n",
        "        #    argmin dist^2 == argmax (x·e) (norm 비슷하다고 보면 dot-product로 충분)\n",
        "        sims = pred_flat @ char_embed.T           # (B*L, V)\n",
        "        pred_ids_flat = sims.argmax(dim=-1)       # (B*L,)\n",
        "        pred_ids = pred_ids_flat.view(B, L)       # (B, L)\n",
        "\n",
        "        return pred_ids"
      ],
      "metadata": {
        "id": "DpObJnaO-1IM"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) backbone 생성\n",
        "backbone = ElectraWithCharEmbedding(peft_model=model, char_embed=char_embed)\n",
        "\n",
        "# 2) RNN 기반 tagger\n",
        "pron_model_rnn = PronunciationTaggerRNN(\n",
        "    backbone=backbone,\n",
        "    num_labels=num_labels,\\\n",
        "    ignore_index=-100,\n",
        ")"
      ],
      "metadata": {
        "id": "5g_kQZ8j9GYA"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "학습 진행"
      ],
      "metadata": {
        "id": "cuXEdLHUXRKH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorForTokenClassification\n",
        "\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n"
      ],
      "metadata": {
        "id": "RUpCGHRYZzu7"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "import numpy as np\n",
        "\n",
        "accuracy_metric = evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    logits_torch = torch.tensor(logits)\n",
        "    predictions_torch = pron_model_rnn.predict_chars(logits_torch)\n",
        "    predictions = predictions_torch.detach().cpu().numpy()\n",
        "\n",
        "    # ignore_index = -100 제거 후 accuracy 계산\n",
        "    mask = labels != -100\n",
        "    y_true = labels[mask]\n",
        "    y_pred = predictions[mask]\n",
        "\n",
        "    if len(y_true) == 0:\n",
        "        return {\"accuracy\": 0.0}\n",
        "\n",
        "    result = accuracy_metric.compute(predictions=y_pred, references=y_true)\n",
        "    return {\"accuracy\": result[\"accuracy\"]}\n"
      ],
      "metadata": {
        "id": "HbhZrK-ZZ0cg"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"kocharelectra-pron-lora\",\n",
        "    learning_rate=5e-3,\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    warmup_ratio=0.1,\n",
        "    per_device_train_batch_size=64,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=10,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    save_total_limit=2,\n",
        "    logging_steps=100,\n",
        "    fp16=True,          # GPU가 지원하면 속도↑\n",
        "    report_to=\"none\",   # wandb 등 안 쓸 거면 none\n",
        "    eval_accumulation_steps=16,\n",
        "    # prediction_loss_only=True,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=pron_model_rnn,\n",
        "    args=training_args,\n",
        "    train_dataset=train_tokenized,\n",
        "    eval_dataset=val_tokenized,\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n"
      ],
      "metadata": {
        "id": "X4C4U3aWZ3B9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d44d948f-9256-41fd-d126-ea4a9c49f0d3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-450319458.py:21: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()\n"
      ],
      "metadata": {
        "id": "uVPgEk5gZ4Jc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "outputId": "e3e5cf2e-6c03-4fb3-fd7e-64f3e03ec804"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py:1621: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1248' max='1570' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1248/1570 09:28 < 02:26, 2.19 it/s, Epoch 7.94/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>5.131600</td>\n",
              "      <td>0.983095</td>\n",
              "      <td>0.044807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.418400</td>\n",
              "      <td>0.217869</td>\n",
              "      <td>0.049898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.227200</td>\n",
              "      <td>0.078465</td>\n",
              "      <td>0.050916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.092100</td>\n",
              "      <td>0.046363</td>\n",
              "      <td>0.051935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.069700</td>\n",
              "      <td>0.037252</td>\n",
              "      <td>0.052953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.047700</td>\n",
              "      <td>0.031129</td>\n",
              "      <td>0.052953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.041400</td>\n",
              "      <td>0.029002</td>\n",
              "      <td>0.053971</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py:1621: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py:1621: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py:1621: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py:1621: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py:1621: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py:1621: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py:1621: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model(save_dir)   # ✅ 모델 가중치 저장 (pytorch_model.bin)\n",
        "tokenizer.save_pretrained(save_dir)\n",
        "\n",
        "# 발음 vocab도 같이 저장\n",
        "with open(os.path.join(save_dir, \"pron_vocab.json\"), \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(pron2id, f, ensure_ascii=False, indent=2)\n"
      ],
      "metadata": {
        "id": "9t_kFopbZ6cz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inference"
      ],
      "metadata": {
        "id": "mI4zM3h1GQGN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from safetensors.torch import load_file\n",
        "\n",
        "# 1) pron_vocab 로드\n",
        "with open(os.path.join(save_dir, \"pron_vocab.json\"), encoding=\"utf-8\") as f:\n",
        "    pron2id = json.load(f)\n",
        "id2pron = {v: k for k, v in pron2id.items()}\n",
        "\n",
        "# 3) safetensors 로드\n",
        "state = load_file(os.path.join(save_dir, \"model.safetensors\"))\n",
        "pron_model_rnn.load_state_dict(state, strict=False)\n",
        "pron_model_rnn.to('cuda')\n",
        "\n",
        "# 4) tokenizer 로드\n",
        "tokenizer = KoCharElectraTokenizer.from_pretrained(save_dir)"
      ],
      "metadata": {
        "id": "MogW9hduVolI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer, return_tensors=\"pt\")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_tokenized,\n",
        "    batch_size=32,\n",
        "    shuffle=False,\n",
        "    collate_fn=data_collator,\n",
        ")\n",
        "\n",
        "device = next(pron_model_rnn.parameters()).device\n",
        "pron_model_rnn.eval()\n",
        "\n",
        "all_pred_ids = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "        output = pron_model_rnn.forward(\n",
        "            input_ids=batch[\"input_ids\"],\n",
        "            attention_mask=batch[\"attention_mask\"],\n",
        "            token_type_ids=batch.get(\"token_type_ids\", None),\n",
        "        )  # (B, L)\n",
        "        pred_ids = pron_model_rnn.predict_chars(output[\"logits\"])\n",
        "\n",
        "        # GPU → CPU → numpy\n",
        "        pred_ids = pred_ids.cpu().numpy()\n",
        "        masks = batch[\"attention_mask\"].cpu().numpy()\n",
        "        input_ids = batch[\"input_ids\"].cpu()\n",
        "        labels = batch[\"labels\"].cpu()\n",
        "\n",
        "        texts = tokenizer.batch_decode(\n",
        "            input_ids,\n",
        "            skip_special_tokens=True\n",
        "        )\n",
        "\n",
        "        B = input_ids.size(0)\n",
        "\n",
        "        for i in range(B):\n",
        "            seq_ids = pred_ids[i]\n",
        "            mask = masks[i]\n",
        "            text = texts[i]\n",
        "            label = labels[i]\n",
        "            valid = (label != -100)\n",
        "\n",
        "            pred = [\n",
        "                id2pron[int(idx)]\n",
        "                for idx, m in zip(seq_ids.tolist(), valid.tolist())\n",
        "                if m\n",
        "            ]\n",
        "\n",
        "            gold = []\n",
        "            for idx, m in zip(label.tolist(), valid.tolist()):\n",
        "                if not m:\n",
        "                    continue\n",
        "                if idx == -100:\n",
        "                    continue\n",
        "                gold.append(id2pron[int(idx)])\n",
        "\n",
        "            print(\"TEXT:\", text)\n",
        "            print(\"PRED:\", \"\".join(pred))\n",
        "            print(\"GOLD:\", \"\".join(gold))\n",
        "            print(\"-\" * 60)"
      ],
      "metadata": {
        "id": "PnUvikguGP8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()\n"
      ],
      "metadata": {
        "id": "4NUq-icot7Gk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}