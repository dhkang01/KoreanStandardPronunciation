{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!rm -rf KoreanStandardPronunciation\n",
        "!git clone https://github.com/dhkang01/KoreanStandardPronunciation.git\n",
        "%cd KoreanStandardPronunciation\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQXr7aQYqQ-d",
        "outputId": "b662b9aa-085e-47d9-f75d-6e4b0d409d20"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'KoreanStandardPronunciation'...\n",
            "remote: Enumerating objects: 19, done.\u001b[K\n",
            "remote: Counting objects: 100% (19/19), done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 19 (delta 5), reused 19 (delta 5), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (19/19), 65.16 KiB | 1.05 MiB/s, done.\n",
            "Resolving deltas: 100% (5/5), done.\n",
            "/content/KoreanStandardPronunciation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q \"transformers>=4.38.0\" \"datasets>=2.18.0\" \"peft>=0.11.0\" accelerate huggingface_hub evaluate"
      ],
      "metadata": {
        "id": "R7c-gPQIWyx3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09ca75c2-ed94-46c5-bea9-ef09325a7031"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/84.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UH7gLzX7SvVo"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset_id = \"dhkang01/KMA_dataset\"\n",
        "raw_ds = load_dataset(dataset_id, split=\"train\")\n",
        "\n",
        "raw_ds"
      ],
      "metadata": {
        "id": "jnRX4nxUW1om"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds_train_val = raw_ds.train_test_split(test_size=0.05, seed=42)\n",
        "train_ds = ds_train_val[\"train\"]\n",
        "val_ds   = ds_train_val[\"test\"]\n"
      ],
      "metadata": {
        "id": "pHHd_N49W40V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenizer 다운로드"
      ],
      "metadata": {
        "id": "WFgn1ry0XLLl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from KoCharELECTRA.tokenization_kocharelectra import KoCharElectraTokenizer\n",
        "\n",
        "model_name = \"monologg/kocharelectra-small-discriminator\"\n",
        "\n",
        "tokenizer = KoCharElectraTokenizer.from_pretrained(model_name)\n",
        "print(tokenizer.tokenize(\"가나다\"))"
      ],
      "metadata": {
        "id": "f9JuUUxXW6Ke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "output vocab"
      ],
      "metadata": {
        "id": "mSW8hqgWZCeA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "\n",
        "# tokenizer.vocab은 OrderedDict(토큰 → ID)\n",
        "token_list = list(tokenizer.vocab.keys())\n",
        "\n",
        "pron2id = OrderedDict()\n",
        "for idx, tok in enumerate(token_list):\n",
        "    pron2id[tok] = idx\n",
        "\n",
        "id2pron = {v: k for k, v in pron2id.items()}\n",
        "\n",
        "len(pron2id), list(list(pron2id.items())[:10])"
      ],
      "metadata": {
        "id": "Ac7KYkFwW9xP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "전처리 함수 정의 및 적용\n",
        "\n",
        "복수 발음 허용 X"
      ],
      "metadata": {
        "id": "C_BE4tNIMB8L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "max_length = 128  # 필요에 따라 조절\n",
        "\n",
        "def preprocess_example(example):\n",
        "    text = example[\"input\"]\n",
        "    pron = example[\"output\"]  # List[List[str]]\n",
        "\n",
        "    # KoCharElectra는 char 단위 토큰 + [CLS], [SEP]\n",
        "    encoding = tokenizer(\n",
        "        text,\n",
        "        truncation=True,\n",
        "        max_length=max_length,\n",
        "        padding=\"max_length\",  # DataCollator 써도 되지만 여기서는 고정 길이로\n",
        "        return_tensors=None,\n",
        "    )\n",
        "\n",
        "    input_ids = encoding[\"input_ids\"]\n",
        "    attention_mask = encoding[\"attention_mask\"]\n",
        "\n",
        "    # Electra/KoCharElectra: 대체로 [CLS] + chars + [SEP]\n",
        "    # => 실제 문자 수 = len(text)\n",
        "    # => pron 길이와 len(text)가 맞는다고 가정 (안 맞는 샘플은 나중에 필터 가능)\n",
        "    seq_len = sum(attention_mask)  # 실제 non-pad 길이\n",
        "    # [CLS] at 0, [SEP] at seq_len-1, chars in 1..seq_len-2\n",
        "\n",
        "    labels = np.full_like(input_ids, fill_value=-100)  # default ignore_index\n",
        "\n",
        "    # 문자 수와 pron 길이 안 맞으면 그냥 전부 ignore(-100)로 두고 스킵되게 할 수도 있음\n",
        "    # 여기선 일단 최소한으로만 체크\n",
        "    n_chars = seq_len - 2  # CLS, SEP 제외\n",
        "\n",
        "    if len(pron) != n_chars:\n",
        "        # 불일치하는 경우: 전부 padding label로 두고, 나중에 이런 샘플 비율 보고 판단\n",
        "        print(f\"Warning: pron len {len(pron)} != n_chars {n_chars} for text: {text}\")\n",
        "        print(f\"in the case, pron: {\"\".join([l[0] for l in pron])}\")\n",
        "        encoding[\"labels\"] = labels.tolist()\n",
        "        return encoding\n",
        "\n",
        "    for i in range(len(pron)):\n",
        "        cand_list = pron[i]\n",
        "        if not cand_list:\n",
        "            continue\n",
        "        gold_pron = cand_list[0]               # 첫 후보를 gold label로 사용\n",
        "        label_id = pron2id[gold_pron]\n",
        "        token_pos = 1 + i                      # 0: [CLS], 1.. : chars\n",
        "        if token_pos < seq_len - 1:            # 마지막 [SEP] 전까지만\n",
        "            labels[token_pos] = label_id\n",
        "\n",
        "    encoding[\"labels\"] = labels.tolist()\n",
        "    return encoding"
      ],
      "metadata": {
        "id": "WL0yWezbW_J5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_tokenized = train_ds.map(\n",
        "    preprocess_example,\n",
        "    remove_columns=train_ds.column_names,\n",
        ")\n",
        "\n",
        "val_tokenized = val_ds.map(\n",
        "    preprocess_example,\n",
        "    remove_columns=val_ds.column_names,\n",
        ")\n",
        "\n",
        "# too long seq is out.\n",
        "\n",
        "train_tokenized[0]\n"
      ],
      "metadata": {
        "id": "fWYWScxeXBJD",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 로드, LoRA 적용\n",
        "\n",
        "encoder에 LoRA적용\n",
        "classifier에 LoRA적용X, 전부 trainable"
      ],
      "metadata": {
        "id": "AQJtsdUuZsz2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForTokenClassification\n",
        "\n",
        "num_labels = len(pron2id)\n",
        "\n",
        "base_model = AutoModelForTokenClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=num_labels,\n",
        ")\n"
      ],
      "metadata": {
        "id": "iPrWeE7UZv5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    task_type=TaskType.TOKEN_CLS,\n",
        "    r=8,\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"none\",\n",
        "    target_modules=[\"query\", \"key\", \"value\", \"dense\"]  # Electra의 attention/FFN 모듈 이름 기준\n",
        ")\n",
        "\n",
        "# print(base_model)\n",
        "model = get_peft_model(base_model, lora_config)\n",
        "model.print_trainable_parameters()\n"
      ],
      "metadata": {
        "id": "EfF1Z-tBZxt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Concat wrapper 모듈 적용"
      ],
      "metadata": {
        "id": "5xhGm5XXVh_t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class ElectraConcatEmbeddingClassifier(nn.Module):\n",
        "    def __init__(self, peft_model, num_labels):\n",
        "        super().__init__()\n",
        "        self.peft_model = peft_model  # PeftModelForTokenClassification\n",
        "        # base_model = ElectraForTokenClassification\n",
        "        self.base_model = peft_model.base_model\n",
        "\n",
        "        self.electra = self.base_model.electra   # ElectraModel (LoRA 포함)\n",
        "        self.num_labels = num_labels\n",
        "\n",
        "        config = self.base_model.config\n",
        "        hidden_size = config.hidden_size          # 256\n",
        "        embed_dim = self.electra.embeddings.word_embeddings.embedding_dim  # 128\n",
        "\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "        concat_dim = hidden_size + embed_dim      # 256 + 128 = 384\n",
        "\n",
        "        # 새 classifier: [encoder_hidden; embedding] → num_labels\n",
        "        self.classifier = nn.Linear(concat_dim, num_labels)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids=None,\n",
        "        attention_mask=None,\n",
        "        token_type_ids=None,\n",
        "        labels=None,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        # 1) input embedding\n",
        "        embedding_output = self.electra.embeddings(\n",
        "            input_ids=input_ids,\n",
        "            token_type_ids=token_type_ids,\n",
        "        )  # (B, L, embed_dim)\n",
        "\n",
        "        # 2) encoder 출력 (LoRA가 여기에 이미 적용됨)\n",
        "        encoder_outputs = self.electra(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "        )\n",
        "        sequence_output = encoder_outputs.last_hidden_state  # (B, L, hidden_size)\n",
        "\n",
        "        # 3) concat\n",
        "        concat = torch.cat([sequence_output, embedding_output], dim=-1)  # (B, L, concat_dim)\n",
        "        concat = self.dropout(concat)\n",
        "\n",
        "        # 4) classifier\n",
        "        logits = self.classifier(concat)  # (B, L, num_labels)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            # labels: (B, L), ignore_index = -100\n",
        "            loss_fct = nn.CrossEntropyLoss(ignore_index=-100)\n",
        "            loss = loss_fct(\n",
        "                logits.view(-1, self.num_labels),\n",
        "                labels.view(-1),\n",
        "            )\n",
        "\n",
        "        # Trainer는 dict 또는 ModelOutput을 받아도 됨\n",
        "        return {\"loss\": loss, \"logits\": logits}\n",
        "\n",
        "    def state_dict(self, *args, **kwargs):\n",
        "        # PEFT 모델의 state_dict만 사용 (중복 경로 제거)\n",
        "        peft_sd = self.peft_model.state_dict(*args, **kwargs)\n",
        "        # 우리 커스텀 classifier도 같이 저장하려면 key를 얹어서 합쳐줌\n",
        "        my_sd = {k: v for k, v in super().state_dict(*args, **kwargs).items()\n",
        "                 if k.startswith(\"classifier.\")}\n",
        "        peft_sd.update({f\"concat_head.{k}\": v for k, v in my_sd.items()})\n",
        "        return peft_sd\n",
        "\n",
        "    def load_state_dict(self, state_dict, strict=True):\n",
        "        # 저장할 때 \"concat_head.classifier.xxx\"로 넣었으니 다시 분리\n",
        "        my_state = {}\n",
        "        peft_state = {}\n",
        "        for k, v in state_dict.items():\n",
        "            if k.startswith(\"concat_head.classifier.\"):\n",
        "                my_state[k.replace(\"concat_head.\", \"\")] = v\n",
        "            else:\n",
        "                peft_state[k] = v\n",
        "        # PEFT 쪽 로드\n",
        "        self.peft_model.load_state_dict(peft_state, strict=False)\n",
        "        # 우리 classifier 로드\n",
        "        super().load_state_dict(my_state, strict=False)\n",
        "\n",
        "concat_model = ElectraConcatEmbeddingClassifier(model, num_labels=num_labels)"
      ],
      "metadata": {
        "id": "leZ9e-zDVhlv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "학습 진행"
      ],
      "metadata": {
        "id": "cuXEdLHUXRKH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorForTokenClassification\n",
        "\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n"
      ],
      "metadata": {
        "id": "RUpCGHRYZzu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "import numpy as np\n",
        "\n",
        "accuracy_metric = evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "    # ignore_index = -100 제거 후 accuracy 계산\n",
        "    mask = labels != -100\n",
        "    y_true = labels[mask]\n",
        "    y_pred = predictions[mask]\n",
        "\n",
        "    if len(y_true) == 0:\n",
        "        return {\"accuracy\": 0.0}\n",
        "\n",
        "    result = accuracy_metric.compute(predictions=y_pred, references=y_true)\n",
        "    return {\"accuracy\": result[\"accuracy\"]}\n"
      ],
      "metadata": {
        "id": "HbhZrK-ZZ0cg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"kocharelectra-pron-lora\",\n",
        "    learning_rate=5e-5,\n",
        "    per_device_train_batch_size=128,\n",
        "    per_device_eval_batch_size=32,\n",
        "    num_train_epochs=5,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    save_total_limit=2,\n",
        "    logging_steps=100,\n",
        "    fp16=True,          # GPU가 지원하면 속도↑\n",
        "    report_to=\"none\",   # wandb 등 안 쓸 거면 none\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=concat_model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_tokenized,\n",
        "    eval_dataset=val_tokenized,\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n"
      ],
      "metadata": {
        "id": "X4C4U3aWZ3B9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()\n"
      ],
      "metadata": {
        "id": "uVPgEk5gZ4Jc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_dir = \"kocharelectra-pron-lora-adapter\"\n",
        "model.save_pretrained(save_dir)\n",
        "tokenizer.save_pretrained(save_dir)\n",
        "\n",
        "# 발음 vocab도 같이 저장\n",
        "import json, os\n",
        "with open(os.path.join(save_dir, \"pron_vocab.json\"), \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(pron2id, f, ensure_ascii=False, indent=2)\n"
      ],
      "metadata": {
        "id": "9t_kFopbZ6cz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}